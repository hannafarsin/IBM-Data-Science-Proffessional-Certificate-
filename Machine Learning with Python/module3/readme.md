# 🧠 Module 3: Classification

## 🎯 Learning Objectives
- Compare and contrast characteristics of various classification algorithms.
- Apply **K-Nearest Neighbors (KNN)** and understand how it works.
- Describe and compute classification model evaluation metrics such as **accuracy**, **precision**, **recall**, and **F1-score**.
- Understand and implement **Decision Trees**.
- Explore **Regression Trees** and their differences from classification trees.
- Apply classification models to real-world datasets for prediction tasks.
- Understand the use of **Snap ML** for high-performance machine learning (optional).

---

## 📺 Covered Videos & Readings

### Videos
1. **Introduction to Classification** – 3 min  
2. **K-Nearest Neighbors (KNN)** – 9 min  
3. **Evaluation Metrics in Classification** – 7 min  
4. **Introduction to Decision Trees** – 4 min  
5. **Building Decision Trees** – 10 min

### Readings
- ✅ **Regression Trees** – 10 min

---

## 💻 Hands-on Labs

- ✅ **Lab: KNN** – 25 min  
- ✅ **Lab: Decision Trees** – 15 min  
- ✅ **Lab: Regression Trees** – 20 min  
- 🧪 *(Optional)* **Lab: Faster Credit Card Fraud Detection using Snap ML** – 1 hr  
- 🧪 *(Optional)* **Lab: Faster Taxi Tip Prediction using Snap ML** – 1 hr

---

## 🧪 Assessments
- ✅ **Practice Quiz: Classification**  
- 🏁 **Graded Quiz: Classification** – **Score: 80%**

---

## 📌 Key Concepts

### 🔍 Classification Algorithms
- **K-Nearest Neighbors (KNN)**: Instance-based algorithm that assigns labels based on the most frequent class among the k nearest neighbors.
- **Decision Trees**: A flowchart-like structure that uses feature-based conditions to classify data.
- **Regression Trees**: A variant of decision trees used when the output variable is continuous.

### 🧪 Model Evaluation Metrics
- **Accuracy**: `(TP + TN) / (TP + FP + TN + FN)`
- **Precision**: `TP / (TP + FP)`
- **Recall (Sensitivity)**: `TP / (TP + FN)`
- **F1-score**: Harmonic mean of precision and recall

---
