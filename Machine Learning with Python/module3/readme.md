# ğŸ§  Module 3: Classification

## ğŸ¯ Learning Objectives
- Compare and contrast characteristics of various classification algorithms.
- Apply **K-Nearest Neighbors (KNN)** and understand how it works.
- Describe and compute classification model evaluation metrics such as **accuracy**, **precision**, **recall**, and **F1-score**.
- Understand and implement **Decision Trees**.
- Explore **Regression Trees** and their differences from classification trees.
- Apply classification models to real-world datasets for prediction tasks.
- Understand the use of **Snap ML** for high-performance machine learning (optional).

---

## ğŸ“º Covered Videos & Readings

### Videos
1. **Introduction to Classification** â€“ 3 min  
2. **K-Nearest Neighbors (KNN)** â€“ 9 min  
3. **Evaluation Metrics in Classification** â€“ 7 min  
4. **Introduction to Decision Trees** â€“ 4 min  
5. **Building Decision Trees** â€“ 10 min

### Readings
- âœ… **Regression Trees** â€“ 10 min

---

## ğŸ’» Hands-on Labs

- âœ… **Lab: KNN** â€“ 25 min  
- âœ… **Lab: Decision Trees** â€“ 15 min  
- âœ… **Lab: Regression Trees** â€“ 20 min  
- ğŸ§ª *(Optional)* **Lab: Faster Credit Card Fraud Detection using Snap ML** â€“ 1 hr  
- ğŸ§ª *(Optional)* **Lab: Faster Taxi Tip Prediction using Snap ML** â€“ 1 hr

---

## ğŸ§ª Assessments
- âœ… **Practice Quiz: Classification**  
- ğŸ **Graded Quiz: Classification** â€“ **Score: 80%**

---

## ğŸ“Œ Key Concepts

### ğŸ” Classification Algorithms
- **K-Nearest Neighbors (KNN)**: Instance-based algorithm that assigns labels based on the most frequent class among the k nearest neighbors.
- **Decision Trees**: A flowchart-like structure that uses feature-based conditions to classify data.
- **Regression Trees**: A variant of decision trees used when the output variable is continuous.

### ğŸ§ª Model Evaluation Metrics
- **Accuracy**: `(TP + TN) / (TP + FP + TN + FN)`
- **Precision**: `TP / (TP + FP)`
- **Recall (Sensitivity)**: `TP / (TP + FN)`
- **F1-score**: Harmonic mean of precision and recall

---
